<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1.0"/>
  <title>BodyPix + Aspect-Ratio-Correct Yuki</title>
  <style>
    body, html { margin:0; padding:0; height:100%; }
    #container {
      position: relative;
      width: 100vw;
      height: 100vh;
      background: url('blizzard1.png') center/cover no-repeat;
      overflow: hidden;
    }
    canvas {
      position: absolute;
      top: 0; left: 0;
      width: 100%;
      height: 100%;
      background: transparent;
      object-fit: cover;
    }
    video { display: none; }
  </style>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@3.21.0/dist/tf.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/body-pix@2.2.0/dist/body-pix.min.js"></script>
</head>
<body>
  <div id="container">
    <video id="video" autoplay playsinline></video>
    <canvas id="canvas"></canvas>
  </div>

<!-- Show blezzard1.png background, Yuki.png then masked video -->

  <script>
    async function setupCamera() {
      const video = document.getElementById('video');
      const stream = await navigator.mediaDevices.getUserMedia({
        video: { facingMode: 'user' },
        audio: false
      });
      video.srcObject = stream;
      return new Promise(res => {
        video.onloadedmetadata = () => (video.play(), res(video));
      });
    }

    async function main() {
      const video  = await setupCamera();
      const canvas = document.getElementById('canvas');
      const ctx    = canvas.getContext('2d');
      canvas.width  = video.videoWidth;
      canvas.height = video.videoHeight;

      // Offscreen canvases
      const maskCanvas  = document.createElement('canvas');
      const videoCanvas = document.createElement('canvas');
      [maskCanvas, videoCanvas].forEach(c => {
        c.width  = canvas.width;
        c.height = canvas.height;
      });
      const maskCtx  = maskCanvas.getContext('2d');
      const videoCtx = videoCanvas.getContext('2d');

      // Load Yuki
      const yukiImg = new Image();
      await new Promise(res => {
        yukiImg.onload = res;
        yukiImg.src    = 'yuki.png';
      });

      // Load BodyPix
      const net = await bodyPix.load({
        architecture: 'MobileNetV1',
        outputStride: 16,
        multiplier: 0.75,
      });

      async function renderFrame() {
        // 1) segmentation mask
        const seg = await net.segmentPerson(video, {
          internalResolution: 'medium',
          segmentationThreshold: 0.5,
        });
        const rawMask = bodyPix.toMask(seg);
        maskCtx.putImageData(rawMask, 0, 0);

        // 2) blur for soft edge
        maskCtx.filter = 'blur(10px)';
        maskCtx.drawImage(maskCanvas, 0, 0);
        maskCtx.filter = 'none';

        // 3) draw and punch‐out video on videoCanvas
        videoCtx.clearRect(0, 0, canvas.width, canvas.height);
        videoCtx.drawImage(video, 0, 0, canvas.width, canvas.height);
        videoCtx.globalCompositeOperation = 'destination-out';
        videoCtx.drawImage(maskCanvas, 0, 0, canvas.width, canvas.height);
        videoCtx.globalCompositeOperation = 'source-over';

        // 4) compose final output
        ctx.clearRect(0, 0, canvas.width, canvas.height);

        // — a) draw Yuki, preserving aspect ratio
        const yW = yukiImg.width, yH = yukiImg.height;
        const scale = Math.min(canvas.width / yW, canvas.height / yH);
        const drawW = yW * scale, drawH = yH * scale;
        const drawX = (canvas.width - drawW) / 2;
        const drawY = (canvas.height - drawH) / 2;
        ctx.drawImage(yukiImg, drawX, drawY, drawW, drawH);

        // — b) draw the masked video (with holes where the person was)
        ctx.drawImage(videoCanvas, 0, 0, canvas.width, canvas.height);

        requestAnimationFrame(renderFrame);
      }

      renderFrame();
    }

    main().catch(console.error);
  </script>
</body>
</html>
